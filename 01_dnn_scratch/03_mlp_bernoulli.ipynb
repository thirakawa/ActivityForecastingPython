{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "02_mlp_bernoulli.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98mLiRqPq5X6"
      },
      "source": [
        "# 02：MLPによる2クラス分類\n",
        "\n",
        "---\n",
        "## 目的\n",
        "多層パーセプトロン（Multi Layer Perceptron; MLP）を用いて，乳癌データの2クラス分類を行う．\n",
        "単一サンプルに対するニューラルネットワークの演算と勾配降下法による学習について理解する．\n",
        "\n",
        "また，オンライン学習，バッチ学習および学習を行う際のiteration, epochについても理解する．\n",
        "\n",
        "## モジュールのインポート\n",
        "プログラムの実行に必要なモジュールをインポートします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad0pITKlq5X6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDoxNte_q5X-"
      },
      "source": [
        "## データセットの読み込み\n",
        "実験に使用するデータセットを読み込みます．\n",
        "\n",
        "今回は**Breast Cancer Wisconsin Dataset**を用いて2クラス分類を行います．\n",
        "breast cancer datasetは乳癌のデータセットであり，クラス数は悪性腫瘍 (malignant)と良性腫瘍 (benign) の2クラス，データ数は569（悪性腫瘍 (malignant): 220, 良性腫瘍 (benign): 357）のデータセットです．\n",
        "各データは細胞核の半径や面積，テクスチャ情報を表現した30次元のベクトルデータです．\n",
        "\n",
        "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
        "\n",
        "はじめに，`wget`コマンドを使用して，データセットのファイルをダウンロードします．\n",
        "\n",
        "次に，データと正解ラベルが含まれている`breast_cancer.csv`を読み込みます．\n",
        "読み込んだデータのうち，最初の30列に各データを表現した30次元のベクトルデータが格納されており，最後の1列に正解ラベル`(0, 1)`が格納されています．これらをそれぞれ，`x`と`y`に分割して格納します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DOaxYgVq5X-"
      },
      "source": [
        "# データセットのダウンロード\n",
        "!wget -q http://www.mprg.cs.chubu.ac.jp/~hirakawa/share/tutorial_data/breast_cancer.csv -O breast_cancer.csv\n",
        "\n",
        "# データセットの読み込み\n",
        "breast_cancer_data = np.loadtxt(\"breast_cancer.csv\", dtype=np.float32, delimiter=\",\")\n",
        "x = breast_cancer_data[:, :-1]\n",
        "y = breast_cancer_data[:, -1].astype(np.int32)\n",
        "\n",
        "print(x.shape, x.dtype)\n",
        "print(y.shape, y.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2-rd4Ocq5YB"
      },
      "source": [
        "## データの分割と正規化\n",
        "上記で読み込んだデータを学習用データとテストデータに分割し，正規化を行います．\n",
        "\n",
        "データの分割では，`test_sample_ratio`で，テストに用いるサンプルの割合を指定します．\n",
        "その後，データの総数から，学習とテストにするデータの数を算出し，ランダムにサンプルを振り分けます．\n",
        "このとき，`np.random.seed`はデータをランダムに分割する際のseedです．\n",
        "seedを変更，または指定しないことで，無作為にデータを分割することが可能です．\n",
        "\n",
        "次に正規化を行います．\n",
        "データ$x$の最小値を$x_{min}$，最大値を$x_{max}$としたとき，次の式で正規化を行います．\n",
        "$$x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
        "\n",
        "`np.min`と`np.max`で学習データの最大，最小値を取得し，上記の式に従い0~1の範囲に値を正規化します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFdIG9Tkq5YB"
      },
      "source": [
        "# データの分割\n",
        "test_sample_ratio = 0.2  # テストデータの割合を指定\n",
        "num_data = x.shape[0]    # データの総数\n",
        "num_test = int(num_data * test_sample_ratio)\n",
        "num_train = num_data - num_test\n",
        "\n",
        "np.random.seed(seed=0)\n",
        "random_index = np.random.permutation(num_data)\n",
        "x_train = x[random_index[0:num_train]]\n",
        "y_train = y[random_index[0:num_train]]\n",
        "x_test = x[random_index[num_train:]]\n",
        "y_test = y[random_index[num_train:]]\n",
        "\n",
        "# データの正規化\n",
        "x_min = np.min(x_train, axis=0)\n",
        "x_max = np.max(x_train, axis=0)\n",
        "\n",
        "x_train = (x_train[:, ] - x_min) / (x_max - x_min)\n",
        "x_test = (x_test[:, ] - x_min) / (x_max - x_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZy0LU6oq5YE"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "次に，ニューラルネットワーク（多層パーセプトロン）を定義します．\n",
        "\n",
        "まずはじめに，ネットワークの定義に必要な関数を定義します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJ2pIC0q5YE"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_grad(x):\n",
        "    return (1.0 - sigmoid(x)) * sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHDkHmvKq5YG"
      },
      "source": [
        "上で定義した関数を用いてネットワークモデルを作成します．\n",
        "ここでは，入力層，中間層，出力層から構成される多層パーセプトロンを定義することとし，1サンプルのデータを入力して結果を出力するようなネットワークを定義します．\n",
        "\n",
        "入力層と中間層のユニット数は引数として与え，それぞれ`input_size`，`hidden_size`とします．\n",
        "出力層サイズについては，今回は2クラス分類問題を扱うため，`0~1`でどちらのクラスに属するかを表現するように，ユニット数は1に固定します．\n",
        "そして，`__init__`関数を用いて，ネットワークのパラメータを初期化します．\n",
        "`w1`および`w2`は各層の重みで，`b1`および`b2`はバイアスを表しています．\n",
        "重みは`randn`関数で，標準正規分布に従った乱数で生成した値を保有する配列を生成します．\n",
        "バイアスは`zeros`関数を用いて，要素が全て0の配列を生成します．\n",
        "\n",
        "そして，`forward`関数で，データを入力して結果を出力するための演算を定義します．\n",
        "\n",
        "次に，`backward`関数ではパラメータの更新量を計算します．\n",
        "まず，ネットワークの出力結果と教師ラベルから，誤差`dy`を算出します．\n",
        "その後，連鎖律に基づいて，出力層から順番に勾配を計算していきます．\n",
        "このとき，パラメータの更新量を`self.grads`へ保存しておきます．\n",
        "\n",
        "また，`update_parameters`関数で，更新量をもとにパラメータの更新を行う関数を定義します．ここでは，`backward`関数によって計算した勾配と更新量（`lr`）によって，現在のパラメータを更新します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkmIaqnrq5YG"
      },
      "source": [
        "class MLPBernoulli:\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, w_std=0.01):\n",
        "        self.w1 = w_std * np.random.randn(input_size, hidden_size)\n",
        "        self.b1 = np.zeros(hidden_size)\n",
        "        self.w2 = w_std * np.random.randn(hidden_size, 1)\n",
        "        self.b2 = np.zeros(1)        \n",
        "        self.grads = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.h1 = np.dot(x, self.w1) + self.b1\n",
        "        self.h2 = sigmoid(self.h1)\n",
        "        self.h3 = np.dot(self.h2, self.w2) + self.b2\n",
        "        self.y = sigmoid(self.h3)\n",
        "        return self.y\n",
        "\n",
        "    def backward(self, x, t): \n",
        "        self.grads = {}\n",
        "\n",
        "        dy = -1 * (t - self.y)\n",
        "        d_h3 = sigmoid_grad(self.h3) * dy\n",
        "        self.grads['w2'] = np.dot(self.h2.T, d_h3)\n",
        "        self.grads['b2'] = np.sum(d_h3, axis=0)\n",
        "\n",
        "        d_h2 = np.dot(d_h3, self.w2.T)\n",
        "        d_h1 = sigmoid_grad(self.h1) * d_h2\n",
        "        self.grads['w1'] = np.dot(x.T, d_h1)\n",
        "        self.grads['b1'] = np.sum(d_h1, axis=0)\n",
        "\n",
        "    def update_parameters(self, lr=0.1):\n",
        "        self.w1 -= lr * self.grads['w1']\n",
        "        self.b1 -= lr * self.grads['b1']\n",
        "        self.w2 -= lr * self.grads['w2']\n",
        "        self.b2 -= lr * self.grads['b2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLxHx6n2q5YJ"
      },
      "source": [
        "## ネットワークの作成と学習の準備\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "\n",
        "まず，中間層と出力層のユニット数を定義します．\n",
        "ここでは，入力層のユニット数`input_size`を学習データの次元，中間層のユニット数`hidden_size`を64とします．\n",
        "\n",
        "各層のユニット数を`MLPBernoulli`クラスの引数として与え，ネットワークを作成します．\n",
        "\n",
        "### ミニバッチ学習で扱うデータ（配列）の形式\n",
        "作成したネットワークへの入力と出力，教師ラベルのデータ配列のサイズ・形を確認します．\n",
        "ここでは，上で用意したデータセット（`x_train`, `y_train`）のうち，先頭の10サンプルを`input`, `label`として保存します．\n",
        "その後，`input`データを`model.forward()`関数に入力し，分類結果を`y`として受け取ります．\n",
        "\n",
        "**※ ネットワークの学習はまだ行われていないため，分類結果は正しいものとは限らないことに注意してください．**\n",
        "\n",
        "ここで，入力，出力，教師ラベルの配列サイズを確認します．\n",
        "入力データは，`(1, 30)`となっており，1次元目がミニバッチサイズに対応しており，2次元目が各サンプルの特徴次元数となっています．\n",
        "また，出力データのサイズは`(1, 1)`となっており，入力と同様に1次元目がミニバッチサイズ，2次元目は各サンプルの出力次元数となっています．このネットワークでは分類結果を0~1のスコアで出力するため，次元数は1となっています．\n",
        "また，`y_train`から取り出した教師ラベルのサイズは`(1,)`となっており，1次元の配列（ベクトル）となっています．\n",
        "学習時の誤差計算に使用するためには，出力データと配列の形を合わせる必要があります．そのために，`reshape()`という関数を適用し，配列の形状を変更することで，対応します．\n",
        "`reshape(-1, 1)`では，2次元の配列に変更しており，2次元目のサイズを1，1次元目のサイズを-1とすることで任意のサイズに変更します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjpJfKNq5YJ"
      },
      "source": [
        "input_size = x.shape[1]\n",
        "hidden_size = 64\n",
        "model = MLPBernoulli(input_size=input_size, hidden_size=hidden_size)\n",
        "\n",
        "# 確認用データの準備\n",
        "input = x_train[0:1]\n",
        "print(\"input data shape:\", input.shape)\n",
        "\n",
        "y = model.forward(input)\n",
        "print(\"output data shape:\", y.shape)\n",
        "\n",
        "label = y_train[0:1]\n",
        "print(\"label data shape:\", label.shape)\n",
        "print(\"label data shape (reshaped):\", label.reshape(-1, 1).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OA5TV0q5YL"
      },
      "source": [
        "## 1サンプルずつの学習（オンライン学習）\n",
        "読み込んだbreast cancerデータセットと作成したネットワークを用いて，学習を行います．\n",
        "ここでは1サンプルずつデータを入力た場合のその出力結果と教師ラベルから誤差を算出し，パラメータの更新を行います．\n",
        "このように，データセット内のサンプルを一つづつ使用して学習を行う方法を**オンライン学習**と呼びます．\n",
        "\n",
        "---\n",
        "### iterationとepoch\n",
        "ニューラルネットワークの学習を行う際には，学習回数の数え方に**iteration**と**epoch**が存在します．\n",
        "1回のパラメータ更新は1 iterationであり，データセット内のデータを全て使用して学習した場合に1 epochとなります．\n",
        "すなわち，iterationは1回のパラメータ更新の単位であり，epochはデータセット1回分の学習を行なった場合の単位です．\n",
        "\n",
        "今回の実験では，1回の誤差を算出するデータ数は前述したように1，学習エポック数は100エポックとします．\n",
        "すなわち，1サンプルごとのパラメータ更新を「データセット内のサンプル数$\\times$エポック数」分繰り返し学習を行います．\n",
        "\n",
        "---\n",
        "\n",
        "上で作成したデータセットを用いて学習を行いますが，学習とテストデータに分割する際にランダムにシャッフルしているため，今回はランダムに並べ替えられたデータを先頭から順番に使用して学習を行います．\n",
        "各更新において，学習用データと教師データをそれぞれ`input`と`label`とします．\n",
        "学習モデルに`input`を与えて，分類結果である`y_pred`を取得します．\n",
        "取得した`y_pred`は精度および誤差を算出するための関数へと入力され，値を保存します．\n",
        "次に，誤差を`backward`関数で逆伝播し，`update_parameters`でネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WGrddJGq5YM"
      },
      "source": [
        "# 学習途中の精度を確認するための関数\n",
        "def binary_classification_accuracy(pred, true):\n",
        "    pred = pred.flatten()\n",
        "    clf_res = np.zeros(pred.shape, dtype=np.int32)\n",
        "    clf_res[pred > 0.5] = 1\n",
        "    return np.sum(clf_res == true).astype(np.float32)\n",
        "\n",
        "# 実験用パラメータの設定\n",
        "num_train_data = x_train.shape[0]\n",
        "num_test_data = x_test.shape[0]\n",
        "epoch_num = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "epoch_list = []\n",
        "itr_list = []\n",
        "itr_loss_list = []\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "iteration = 0\n",
        "for epoch in range(1, epoch_num + 1, 1):\n",
        "    sum_accuracy = 0.0\n",
        "    sum_loss = 0.0\n",
        "\n",
        "    for i in range(0, num_train_data, 1):\n",
        "        input = x_train[i:i+1]\n",
        "        label = y_train[i:i+1]\n",
        "\n",
        "        y_pred = model.forward(input)\n",
        "\n",
        "        sum_accuracy += binary_classification_accuracy(y_pred, label)\n",
        "        sum_loss += np.sum(np.power(y_pred - label, 2))\n",
        "        itr_loss_list.append(np.sum(np.power(y_pred - label, 2)))\n",
        "        itr_list.append(iteration)\n",
        "\n",
        "        model.backward(input, label.reshape(-1, 1))\n",
        "        model.update_parameters(lr=learning_rate)\n",
        "        \n",
        "        iteration += 1\n",
        "\n",
        "    if epoch % 10 == 0:       \n",
        "        print(\"epoch: {} (iteration: {}), mean loss: {}, mean accuracy: {}\".format(epoch, iteration,\n",
        "                                                                   sum_loss / num_train_data,\n",
        "                                                                   sum_accuracy / num_train_data))\n",
        "    \n",
        "    test_correct_count = 0\n",
        "    for i in range(num_test_data):\n",
        "        input = x_test[i]\n",
        "        label = y_test[i]\n",
        "        y = model.forward(input)\n",
        "        \n",
        "        if y[0] > 0.5:\n",
        "            pred = 1\n",
        "        else:\n",
        "            pred = 0\n",
        "        if pred == label:\n",
        "            test_correct_count += 1\n",
        "\n",
        "    # 学習途中のlossと精度の保存\n",
        "    epoch_list.append(epoch)\n",
        "    train_loss_list.append(sum_loss / num_train_data)\n",
        "    train_accuracy_list.append(sum_accuracy / num_train_data)\n",
        "    test_accuracy_list.append(test_correct_count / num_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDiUt_aYq5YO"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークを用いて，テストデータに対する認識率の確認を行います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-1oIoU5q5YO"
      },
      "source": [
        "count = 0\n",
        "num_test_data = x_test.shape[0]\n",
        "\n",
        "for i in range(num_test_data):\n",
        "    input = x_test[i]\n",
        "    label = y_test[i]\n",
        "    y = model.forward(input)\n",
        "    \n",
        "    if y[0] > 0.5:\n",
        "        pred = 1\n",
        "    else:\n",
        "        pred = 0\n",
        "    \n",
        "    if pred == label:\n",
        "        count += 1\n",
        "\n",
        "print(\"test accuracy: {}\".format(count / num_test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvhwd_ZAfgBw"
      },
      "source": [
        "## 学習推移のグラフ化\n",
        "\n",
        "上の学習プログラムで保存しておいた誤差および精度のデータをグラフ化します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPcggZkldwxa"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(epoch_list, train_loss_list, label='loss (train)')\n",
        "plt.xlabel(\"epoch\")     # x軸ラベル\n",
        "plt.ylabel(\"loss\")      # y軸ラベル\n",
        "plt.legend()            # 凡例\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(itr_list, itr_loss_list, label='loss (train)')\n",
        "plt.xlabel(\"iteration\")     # x軸ラベル\n",
        "plt.ylabel(\"loss\")      # y軸ラベル\n",
        "plt.legend()            # 凡例\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch_list, train_accuracy_list, label='accuracy (train)')\n",
        "plt.plot(epoch_list, test_accuracy_list, label='accuracy (test)')\n",
        "plt.xlabel(\"epoch\")     # x軸ラベル\n",
        "plt.ylabel(\"accuracy\")  # y軸ラベル\n",
        "plt.legend()            # 凡例\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4BWkbwMwNO7"
      },
      "source": [
        "## 課題\n",
        "1. \"ネットワークの作成\"から実行し直した際の認識率を比較してみよう\n",
        "2. 学習率を変更した際の学習の推移を確認してみよう\n",
        "3. 中間層のサイズを変更した際の精度と学習の推移を比較して考察しよう"
      ]
    }
  ]
}